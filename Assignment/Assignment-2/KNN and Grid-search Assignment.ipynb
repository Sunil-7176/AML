{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "### 1. train test split from scratch\n",
    "\n",
    "Create a function my_train_test_split() that takes ipnput X, y and fraction of train. And ouputs the list or tuple containing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clue 1: Splitting the data sequentially for a given fraction\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0], [9, 10, 1], [11, 12, 0]])\n",
    "print('data:')\n",
    "print(data)\n",
    "\n",
    "# Train part of the data\n",
    "split = int(0.8*data.shape[0])\n",
    "X_train = data[:split, :-1]\n",
    "y_train = data[:split, -1]\n",
    "\n",
    "print('\\nX_train:')\n",
    "print(X_train)\n",
    "print('\\ny_train:')\n",
    "print(y_train)\n",
    "\n",
    "# The test part of the data\n",
    "X_test = data[split:, :-1]\n",
    "y_test = data[split:, -1]\n",
    "\n",
    "print('\\ny_train:')\n",
    "print(X_test)\n",
    "\n",
    "print('\\ny_test:')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clue2: splitting data randomly\n",
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0]])\n",
    "num_samples = data.shape[0]\n",
    "ind = np.random.choice(num_samples, num_samples, replace = False)\n",
    "print(ind)\n",
    "print(type(ind))\n",
    "split = int(0.8*num_samples)\n",
    "print(split)\n",
    "ind[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your function definition goes here\n",
    "def train_test_split(X,y, test_size, random_state):\n",
    "    num_samples = data.shape[0]\n",
    "    split = int(0.8*data.shape[0])\n",
    "\n",
    "    X_train = X[:split]\n",
    "    y_train = y[:split]\n",
    "    X_test = X[split:]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    return np.array(X_train),  np.array(X_test), np.array(y_train), np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your function invocation goes here\n",
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0], [9, 10, 1], [11, 12, 0]])\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"\\ny_train:\")\n",
    "print(y_train)\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test)\n",
    "print(\"\\ny_test:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. kNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN class that allows setting the number of neighbours and weight=uniform or distance\n",
    "class KNN:\n",
    "    def __init__(self, k=3): #Fill this out\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self,X, y): # What is missing in function definition?\n",
    "        self.X_train = X\n",
    "        self.y_train=y\n",
    "\n",
    "    def predict(self,X_test): # What is missing in function definition?\n",
    "        predictions = []\n",
    "        for test_sample in X_test:\n",
    "            distances = [np.linalg.norm(test_sample - train_sample) for train_sample in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            most_common_label = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "            predictions.append(most_common_label)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "knn = KNN()\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(pred, y_test)\n",
    "print(f\"Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GridSearch from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_grid_search(X_train,y_train,X_test,param_grid,k_values):\n",
    "    best_params=None\n",
    "    best_accuracy=-1\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNN(k=k)\n",
    "        knn.fit(X_train,y_train)\n",
    "        predictions = knn.predict(X_test)\n",
    "        accuracy = (predictions==y_test).mean()\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "           best_accuracy = accuracy\n",
    "           best_params = {'n_neighbors': k} \n",
    "        \n",
    "    return best_params, best_accuracy\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "\n",
    "best_params, best_accuracy = my_grid_search(X_train, y_train, X_test, param_grid, k_values)\n",
    "\n",
    "print(\"Best K value found:\", best_params['n_neighbors'])\n",
    "print(\"Accuracy of the best model:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Integrate your custom code\n",
    "\n",
    "1. Create a dataframe of iris dataset\n",
    "2. Use your custom train test split function to split into train and test\n",
    "3. Use your custom GridSearch on your customKNN class to identify the best k and best weight for iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "def train_test_split(X,y, test_size, random_state):\n",
    "    num_samples = data.shape[0]\n",
    "    split = int(0.8*data.shape[0])\n",
    "\n",
    "    X_train = X[:split]\n",
    "    y_train = y[:split]\n",
    "    X_test = X[split:]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    return np.array(X_train),  np.array(X_test), np.array(y_train), np.array(y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"\\ny_train:\")\n",
    "print(y_train)\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test)\n",
    "print(\"\\ny_test:\")\n",
    "print(y_test)\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3): #Fill this out\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self,X, y): # What is missing in function definition?\n",
    "        self.X_train = X\n",
    "        self.y_train=y\n",
    "\n",
    "    def predict(self,X_test): # What is missing in function definition?\n",
    "        predictions = []\n",
    "        for test_sample in X_test:\n",
    "            distances = [np.linalg.norm(test_sample - train_sample) for train_sample in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            most_common_label = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "            predictions.append(most_common_label)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "knn = KNN()\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(pred, y_test)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "\n",
    "def my_grid_search(X_train,y_train,X_test,param_grid,k_values):\n",
    "    best_params=None\n",
    "    best_accuracy=-1\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNN(k=k)\n",
    "        knn.fit(X_train,y_train)\n",
    "        predictions = knn.predict(X_test)\n",
    "        accuracy = (predictions==y_test).mean()\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "           best_accuracy = accuracy\n",
    "           best_params = {'n_neighbors': k} \n",
    "        \n",
    "    return best_params, best_accuracy\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "\n",
    "best_params, best_accuracy = my_grid_search(X_train, y_train, X_test, param_grid, k_values)\n",
    "\n",
    "print(\"Best K value found:\", best_params['n_neighbors'])\n",
    "print(\"Accuracy of the best model:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
